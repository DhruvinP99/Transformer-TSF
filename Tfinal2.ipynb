{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the data from GitHub and skip problematic line\n",
    "\n",
    "url = 'https://github.com/DhruvinP99/Transformer-TSF/raw/main/illinois_data3.csv'\n",
    "\n",
    "try:\n",
    "\n",
    "    data = pd.read_csv(url)\n",
    "\n",
    "except pd.errors.ParserError as e:\n",
    "\n",
    "    print(f\"ParserError: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Display the first few rows to understand the structure of your data\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example: Assuming 'week' as index and 'UNWEIGHTED ILI' as the target column\n",
    "\n",
    "# Ensure 'week' is indeed a column in your DataFrame\n",
    "\n",
    "if ' week' in data.columns:\n",
    "\n",
    "    data[' week'] = pd.to_datetime(data[' week'])\n",
    "\n",
    "    data.set_index(' week', inplace=True)\n",
    "\n",
    "    print(\"Data after setting 'week' as index:\\n\", data.head())\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Column 'week' not found in the data. Please check the column names.\")\n",
    "\n",
    "\n",
    "\n",
    "# Print columns again to verify if there are any extra characters in column names\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "\n",
    "# Remove any leading or trailing whitespace from column names\n",
    "\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'X' with 0 in 'UNWEIGHTED ILI' column\n",
    "\n",
    "data['UNWEIGHTED ILI'] = data['UNWEIGHTED ILI'].replace('X', 0).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data['UNWEIGHTED ILI'] = scaler.fit_transform(data[['UNWEIGHTED ILI']])\n",
    "\n",
    "\n",
    "\n",
    "# Prepare sequences function\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "\n",
    "        x = data.iloc[i:(i + seq_length)].values\n",
    "\n",
    "        y = data.iloc[i + seq_length].values\n",
    "\n",
    "        xs.append(x)\n",
    "\n",
    "        ys.append(y)\n",
    "\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "\n",
    "seq_length = 10  # You can adjust this\n",
    "\n",
    "X, y = create_sequences(data[['UNWEIGHTED ILI']], seq_length)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "\n",
    "train_size = int(0.7 * len(X))\n",
    "\n",
    "val_size = int(0.15 * len(X))\n",
    "\n",
    "test_size = len(X) - train_size - val_size\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "\n",
    "X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "\n",
    "X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n",
    "\n",
    "\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.X)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "\n",
    "val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Positional Encoding class\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "\n",
    "# Transformer model class\n",
    "\n",
    "class TransformerTimeSeries(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout=0.1):\n",
    "\n",
    "        super(TransformerTimeSeries, self).__init__()\n",
    "\n",
    "        self.model_type = 'Transformer'\n",
    "\n",
    "        self.src_mask = None\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "\n",
    "        self.decoder = nn.Linear(d_model, input_dim)  # Ensure the output dimension matches the input dimension\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        output = self.transformer(src, src)\n",
    "\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Set hyperparameters\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "d_model = 512\n",
    "\n",
    "nhead = 8\n",
    "\n",
    "num_encoder_layers = 3\n",
    "\n",
    "num_decoder_layers = 3\n",
    "\n",
    "dim_feedforward = 2048\n",
    "\n",
    "dropout = 0.1\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "\n",
    "model = TransformerTimeSeries(input_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "# Training loop with validation\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    \n",
    "\n",
    "    for inputs, targets in train_dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "\n",
    "        inputs = inputs.permute(1, 0, 2)  # Permute to (seq_length, batch_size, input_dim) for transformer\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        \n",
    "\n",
    "        outputs = outputs.permute(1, 0, 2)  # Permute back to (batch_size, seq_length, input_dim)\n",
    "\n",
    "        targets = targets.unsqueeze(-1)  # Ensure targets have shape (batch_size, 1)\n",
    "\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs[:, -1], targets.squeeze(-1))  # Use only the last prediction for loss calculation\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    \n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {epoch_loss}\")\n",
    "\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for inputs, targets in val_dataloader:\n",
    "\n",
    "            inputs = inputs.permute(1, 0, 2)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "\n",
    "            targets = targets.unsqueeze(-1)\n",
    "\n",
    "            \n",
    "\n",
    "            val_loss += criterion(outputs[:, -1], targets.squeeze(-1)).item()  # Use only the last prediction for loss calculation\n",
    "\n",
    "    \n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "\n",
    "\n",
    "# Plot training and validation loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(range(1, epochs + 1), train_losses, marker='o', label='Training Loss')\n",
    "\n",
    "plt.plot(range(1, epochs + 1), val_losses, marker='o', label='Validation Loss')\n",
    "\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on test set and visualize predictions\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "\n",
    "all_targets = []\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for inputs, targets in test_dataloader:\n",
    "\n",
    "        inputs = inputs.permute(1, 0, 2)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        outputs = outputs.permute(1, 0, 2)\n",
    "\n",
    "        targets = targets.unsqueeze(-1)\n",
    "\n",
    "        \n",
    "\n",
    "        all_targets.extend(targets.squeeze(-1).tolist())\n",
    "\n",
    "        all_predictions.extend(outputs[:, -1].squeeze(-1).tolist())\n",
    "\n",
    "\n",
    "\n",
    "# Rescale the predictions and targets to their original scale\n",
    "\n",
    "all_targets = scaler.inverse_transform(np.array(all_targets).reshape(-1, 1)).flatten()\n",
    "\n",
    "all_predictions = scaler.inverse_transform(np.array(all_predictions).reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "\n",
    "# Ensure all_targets and all_predictions have the same length\n",
    "\n",
    "min_length = min(len(all_targets), len(all_predictions))\n",
    "\n",
    "all_targets = all_targets[:min_length]\n",
    "\n",
    "all_predictions = all_predictions[:min_length]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate RMSE\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(all_targets, all_predictions))\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "\n",
    "corr, _ = pearsonr(all_targets, all_predictions)\n",
    "\n",
    "print(f\"Pearson Correlation Coefficient: {corr}\")\n",
    "\n",
    "\n",
    "\n",
    "# Plot the test results\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(all_targets, marker='o', label='True Values')\n",
    "\n",
    "plt.plot(all_predictions, marker='x', label='Predictions')\n",
    "\n",
    "plt.title('True Values vs Predictions on Test Set')\n",
    "\n",
    "plt.xlabel('Time Step')\n",
    "\n",
    "plt.ylabel('UNWEIGHTED ILI')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
